#!/bin/bash

[ -f /etc/profile.d/hadoop.sh ] && . /etc/profile.d/hadoop.sh
cd $(dirname $0)

# CONFIGURATION SECTION
NAME="streaming join test"
PROJ=join
INPUT_L=base_data_left.txt
INPUT_R=base_data_right.txt
OUTPUT=output/$PROJ
MAPPER=$PROJ-mapper.rb
REDUCER=$PROJ-reducer.rb
REDUCERS=1
# END CONFIGURATION SECTION

RUBY='/usr/local/ruby19/bin/ruby -EASCII-8BIT'
RUBY='/usr/local/jruby/bin/jruby -EASCII-8BIT --1.9 --fast --server'

echo placing the sample data in HDFS...
hadoop fs -put $INPUT_L .
hadoop fs -put $INPUT_R .

echo removing any existing output directory...
hadoop fs -rmr $OUTPUT >&/dev/null

COMPARATOR=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator
# sort key (string) then by join side (numeric ascending)
COMP_OPTS='-k1,1 -k2,2n'

hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-streaming-*.jar \
  -D mapred.job.name="$NAME" \
  -D mapred.reduce.tasks=$REDUCERS \
  -D stream.map.output.field.separator="$(printf '\t')" \
  -D stream.num.map.output.key.fields=2 \
  -D map.output.key.field.separator="$(printf '\t')" \
  -D mapred.output.key.comparator.class=$COMPARATOR \
  -D mapred.text.key.comparator.options="$COMP_OPTS" \
  -D mapred.text.key.partitioner.options=-k1 \
  -D num.key.fields.for.partition=1 \
  -input "$INPUT_L" \
  -input "$INPUT_R" \
  -output "$OUTPUT" \
  -mapper "$RUBY ${MAPPER##*/}" \
  -file $MAPPER \
  -reducer "$RUBY ${REDUCER##*/}" \
  -file $REDUCER

JOB_STATUS=$?

if [ $JOB_STATUS -ne 0 ]; then
  echo error: job exited with status $JOB_STATUS >&2
else
  echo info: job complete...output can be found in $OUTPUT
  hadoop fs -cat $OUTPUT/part*
fi

exit $JOB_STATUS
